<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <title>
    XGBoost applied to Iris dataset // Just my blog
  </title>

  <link href="http://gmpg.org/xfn/11" rel="profile">
<meta http-equiv="content-type" content="text/html; charset=utf-8">


<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="">
<meta name="generator" content="Hugo 0.26" />

  <meta property="og:title" content="XGBoost applied to Iris dataset" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:locale" content="en_US" />
<meta property="og:url" content="http://iryndin.net/post/xgboost_for_iris_dataset/" />


  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/base-min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css">
  
  
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/grids-responsive-min.css">
  
  

  <link rel="stylesheet" href="http://iryndin.net/css/redlounge.css">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
  <link href='//fonts.googleapis.com/css?family=Raleway:400,200,100,700,300,500,600,800' rel='stylesheet' type='text/css'>
  <link href='//fonts.googleapis.com/css?family=Libre+Baskerville:400,700,400italic' rel='stylesheet' type='text/css'>

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/touch-icon-144-precomposed.png">
  <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Just my blog" />

    
  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/styles/tomorrow-night-bright.min.css">
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>


  

  

  

  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', "UA-55566999-1", 'auto');
  ga('send', 'pageview');
</script>

</head>

<body>
	

	<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
  <div class="header">
    

	

    
    

    <nav class="nav">
      <ul class="nav-list">
        <li class="nav-item"><span class="nav-item-separator">//</span><a href="http://iryndin.net">Home</a></li>
        
      </ul>
    </nav>

    

  </div>
</div>

	
	

    <div class="content pure-u-1 pure-u-md-3-4">
		<a name="top"></a>
		

		
			
		    <div id="toc" class="pure-u-1 pure-u-md-1-4">
				<small class="toc-label">Contents</small>
		   	 	<nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#run-jupyter-with-docker-and-install-xgboost">Run Jupyter with Docker and install XGBoost</a></li>
<li><a href="#load-iris-dataset-split-it-to-train-and-test">Load Iris dataset, split it to train and test</a></li>
<li><a href="#train-xgboost-predict-data-and-compare">Train XGBoost, predict data and compare</a></li>
<li><a href="#links">Links</a></li>
</ul></li>
</ul>
</nav>
		    </div>
		    
	    
  		<section class="post">
            <h1 class="post-title">
              <a href="/post/xgboost_for_iris_dataset/">XGBoost applied to Iris dataset</a>
            </h1>
            <h3 class="post-subtitle">
            	
            </h3>
            
            	<span class="post-date">
                	<span class="post-date-day"><sup>10</sup></span><span class="post-date-separator">/</span><span class="post-date-month">Apr</span> <span class="post-date-year">2019</span>
            	</span>
            	
            
            	
            

			
			

			

			

            <p>Let&rsquo;s show here a very simple example of applying XGBoost to Iris dataset. Initial Iris dataset is at <a href="http://archive.ics.uci.edu/ml/datasets/iris">UCI data repository</a>. But we will use ready-to-use <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html">Iris dataset contained in sklearn</a>.</p>

<p></p>

<h2 id="run-jupyter-with-docker-and-install-xgboost">Run Jupyter with Docker and install XGBoost</h2>

<p>Let&rsquo;s run our data science Docker, as described here: <a href="http://iryndin.net/post/run-jupyter-with-docker/">Run Jupyter notebooks with Docker</a>.
Run command:</p>

<pre><code>docker run --rm -p 8888:8888 --name myds1 jupyter/scipy-notebook:latest
</code></pre>

<p>But this Docker image does not contain XGBoost, so let&rsquo;s manually install it.
After container is started, let&rsquo;s exec following command to install XGBoost:</p>

<pre><code>docker exec -it myds1 pip install xgboost
</code></pre>

<h2 id="load-iris-dataset-split-it-to-train-and-test">Load Iris dataset, split it to train and test</h2>

<p>Load necessary imports, load data and split dataset:</p>

<pre><code>import xgboost
from sklearn import datasets
from sklearn.cross_validation import train_test_split

iris = datasets.load_iris()
X = iris.data
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
</code></pre>

<h2 id="train-xgboost-predict-data-and-compare">Train XGBoost, predict data and compare</h2>

<p>XGBoost needs that Numpy arrays be loaded in special DMatrix format:</p>

<pre><code>dtrain = xgboost.DMatrix(X_train, label=y_train)
dtest = xgboost.DMatrix(X_test, label=y_test)
</code></pre>

<p>Then let&rsquo;s set up XGBoost params:</p>

<pre><code>param = {
    'max_depth': 3,                 # the maximum depth of each tree
    'eta': 0.3,                     # the training step for each iteration
    'silent': 1,                    # logging mode - quiet
    'objective': 'multi:softmax',   # multiclass classification using the softmax objective
    'num_class': 3                  # the number of classes that exist in this datset
}  
num_round = 20  # the number of training iterations
</code></pre>

<p>More about XGBoost params can be found here: <a href="https://xgboost.readthedocs.io/en/latest/parameter.html">XGBoost Parameters</a>.</p>

<p>Now train our model. And, if you want to look at how XGBModel looks like, dump it at text file and then simply take a look at it.</p>

<pre><code>bstmodel = xgboost.train(param, dtrain, num_round)
bstmodel.dump_model('dump.bstmodel.txt')
</code></pre>

<p>Then predict on test data and calculate accuracy score:</p>

<pre><code>preds = bst.predict(dtest)

from sklearn import metrics
acc = metrics.accuracy_score(y_test, preds2)
acc
</code></pre>

<p>That is it!</p>

<h2 id="links">Links</h2>

<ul>
<li><a href="http://ieva.rocks/2016/08/25/iris_dataset_and_xgboost_simple_tutorial/">Ieva Zarina - Iris dataset and xgboost simple tutorial</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/">Analytics Vidhya - Complete Guide to Parameter Tuning in XGBoost (with codes in Python)</a></li>
<li><a href="https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e">Towards Data Science - Fine-tuning XGBoost in Python like a boss</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/">Analytics Vidhya - An End-to-End Guide to Understand the Math behind XGBoost</a></li>
<li><a href="https://www.kaggle.com/kernels?search=tag:%27xgboost%27">Kaggle - Kernels using xgboost</a></li>
<li><a href="https://github.com/anktplwl91/fashion_mnist.git">XGBoost on MNIST and Fashion MNIST</a></li>
<li><a href="https://www.kaggle.com/cbrogan/xgboost-example-python">Kaggle - XGBoost on titanic</a></li>
<li><a href="https://www.kaggle.com/anktplwl91/mnist-xgboost">Kaggle - XGBoost on mnist</a></li>
<li><a href="https://dataplatform.cloud.ibm.com/analytics/notebooks/v2/de824290-6811-455b-b2a4-678fd6ae06ee/view?access_token=cb51caafa25bb0e596867d19fd0e96c77baeffca4b561091e38f0cd4476dc682">IBM - XGBoost and breast cancer</a></li>
<li><a href="https://github.com/dmlc/xgboost/tree/master/demo">XGBoost demos from XGBoost Git repo</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2015/12/kaggle-solution-cooking-text-mining-competition/">Analytics Vidhya - Kaggle Solution: Whatâ€™s Cooking ? (Text Mining Competition)</a></li>
<li><a href="https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/">MachineLearningMastery - How to Develop Your First XGBoost Model in Python with scikit-learn</a></li>
<li><a href="ttps://xgboost.readthedocs.io/en/latest/">XGBoost docs</a></li>
<li><a href="https://jessesw.com">jessesw.com - Good data scientist blog</a></li>
</ul>
	
			

			
				<div class="tags-list">
					<span class="dark-red">Tags</span><span class="decorative-marker">//</span>
					
	                <a class="post-tag post-tag-machine-learning" href="http://iryndin.net/tags/machine-learning">machine learning</a>,
	                
	                <a class="post-tag post-tag-xgboost" href="http://iryndin.net/tags/xgboost">xgboost</a>,
	                
				</div>
			

			
				<div class="paging">
					<span class="paging-label">More Reading</span>
					
					<div class="paging-newer">
						<span class="dark-red">Newer</span><span class="decorative-marker">//</span>
						<a class="paging-link" href="/post/xgboost_mnist/">XGBoost applied to MNIST</a>
		            </div>
		            

					
					<div class="paging-older">
						<span class="dark-red">Older</span><span class="decorative-marker">//</span>
			            <a class="paging-link" href="/post/mnist-with-cnn-and-keras/">MNIST digit recognition with CNN and Keras</a>
		            </div>
		            
	            </div>
            
          </section>
          
          	
          
        
      <div class="footer">
	<hr class="thin" />
	<div class="pure-menu pure-menu-horizontal pure-menu-open">
		<ul class="footer-menu">
		
		</ul>
	</div>

	<p>&copy; 2019. All rights reserved.</p>
</div>
    </div>
  </div>
	

	

  
</body>
</html>
