<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <title>
    XGBoost applied to Fashion MNIST // Just my blog
  </title>

  <link href="http://gmpg.org/xfn/11" rel="profile">
<meta http-equiv="content-type" content="text/html; charset=utf-8">


<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="">
<meta name="generator" content="Hugo 0.26" />

  <meta property="og:title" content="XGBoost applied to Fashion MNIST" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:locale" content="en_US" />
<meta property="og:url" content="http://iryndin.net/post/xgboost_fashion_mnist/" />


  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/base-min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css">
  
  
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/grids-responsive-min.css">
  
  

  <link rel="stylesheet" href="http://iryndin.net/css/redlounge.css">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
  <link href='//fonts.googleapis.com/css?family=Raleway:400,200,100,700,300,500,600,800' rel='stylesheet' type='text/css'>
  <link href='//fonts.googleapis.com/css?family=Libre+Baskerville:400,700,400italic' rel='stylesheet' type='text/css'>

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/touch-icon-144-precomposed.png">
  <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Just my blog" />

    
  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/styles/tomorrow-night-bright.min.css">
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>


  

  

  

  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', "UA-55566999-1", 'auto');
  ga('send', 'pageview');
</script>

</head>

<body>
	

	<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
  <div class="header">
    

	

    
    

    <nav class="nav">
      <ul class="nav-list">
        <li class="nav-item"><span class="nav-item-separator">//</span><a href="http://iryndin.net">Home</a></li>
        
      </ul>
    </nav>

    

  </div>
</div>

	
	

    <div class="content pure-u-1 pure-u-md-3-4">
		<a name="top"></a>
		

		
			
		    <div id="toc" class="pure-u-1 pure-u-md-1-4">
				<small class="toc-label">Contents</small>
		   	 	<nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#data">Data</a></li>
<li><a href="#code">Code</a></li>
</ul></li>
</ul>
</nav>
		    </div>
		    
	    
  		<section class="post">
            <h1 class="post-title">
              <a href="/post/xgboost_fashion_mnist/">XGBoost applied to Fashion MNIST</a>
            </h1>
            <h3 class="post-subtitle">
            	
            </h3>
            
            	<span class="post-date">
                	<span class="post-date-day"><sup>12</sup></span><span class="post-date-separator">/</span><span class="post-date-month">Apr</span> <span class="post-date-year">2019</span>
            	</span>
            	
            
            	
            

			
			

			

			

            <p>Now let&rsquo;s consider applying XGBoost to Fashion MNIST dataset. As well as in 2 previous posts about XGBoost data are eready to use,
and do not require any additional preprocessing in order to get accuracy near 90%. This makes this case similar to previous two (Iris and MNIST).</p>

<p></p>

<h2 id="data">Data</h2>

<p>Fashion MNIST dataset can be downloaded from Kaggle: <a href="https://www.kaggle.com/zalando-research/fashionmnist">Kaggle - Fashion MNIST. An MNIST-like dataset of 70,000 28x28 labeled fashion images</a>. Dataset comes as two files:</p>

<ul>
<li><code>fashion-mnist_train.csv</code> - train data, 60 000 data rows</li>
<li><code>fashion-mnist_test.csv</code> - test data, 10 000 data rows</li>
</ul>

<h2 id="code">Code</h2>

<p>Now let&rsquo;s jump into the code.</p>

<p>Import necessary libs:</p>

<pre><code>import numpy as np
import pandas as pd
import xgboost as xgb
</code></pre>

<p>Load train data, split it to one-column data frame with label only and data frame with actual image data. Then convert it to XGBoost <code>DMatrix</code> form.</p>

<pre><code>train = pd.read_csv('./fashion-mnist_train.csv', header=0)
train_label = train['label']
train_data = train.drop(['label'],axis=1)
dtrain = xgb.DMatrix(train_data, label=train_label)
</code></pre>

<p>Define parameters for XGBoost.</p>

<pre><code>param = {
    'max_depth': 5,                 # the maximum depth of each tree
    'eta': 0.3,                     # the training step for each iteration
    'verbosity': 1,                 # logging mode - warn
    'objective': 'multi:softmax',   # multiclass classification using the softmax objective
    'num_class': 10                 # the number of classes that exist in this datset
}  
num_round = 50 # the number of training iterations
</code></pre>

<p>Train our model:</p>

<pre><code>import time
start = time. time()
bstmodel = xgb.train(param, dtrain, num_round, evals=[(dtrain, 'label')], verbose_eval=10)
end = time.time()
exec_time = end - start
print('Execution time, secs: %d' % exec_time)
</code></pre>

<p>Training on my laptop takes <code>350 secs</code>.</p>

<p>Then let&rsquo;s prepare test data in the same fashion as test data:</p>

<pre><code>test = pd.read_csv('./fashion-mnist_test.csv', header=0)

test_label = test['label']
test_data = test.drop(['label'],axis=1)
dtest = xgb.DMatrix(test_data, label=test_label)
</code></pre>

<p>Predict:</p>

<pre><code>preds = bstmodel.predict(dtest)
</code></pre>

<p>Then assess results:</p>

<pre><code>from sklearn import metrics
acc = metrics.accuracy_score(test_label, preds)
print('Accuracy: %f' % acc)
</code></pre>

<p>Accuracy is <code>0.895300</code>.</p>
	
			

			
				<div class="tags-list">
					<span class="dark-red">Tags</span><span class="decorative-marker">//</span>
					
	                <a class="post-tag post-tag-machine-learning" href="http://iryndin.net/tags/machine-learning">machine learning</a>,
	                
	                <a class="post-tag post-tag-xgboost" href="http://iryndin.net/tags/xgboost">xgboost</a>,
	                
	                <a class="post-tag post-tag-fashion-mnist" href="http://iryndin.net/tags/fashion-mnist">fashion mnist</a>,
	                
				</div>
			

			
				<div class="paging">
					<span class="paging-label">More Reading</span>
					
					<div class="paging-newer">
						<span class="dark-red">Newer</span><span class="decorative-marker">//</span>
						<a class="paging-link" href="/post/ad_exchange_core/">Ad Exchange core implementation</a>
		            </div>
		            

					
					<div class="paging-older">
						<span class="dark-red">Older</span><span class="decorative-marker">//</span>
			            <a class="paging-link" href="/post/xgboost_mnist/">XGBoost applied to MNIST</a>
		            </div>
		            
	            </div>
            
          </section>
          
          	
          
        
      <div class="footer">
	<hr class="thin" />
	<div class="pure-menu pure-menu-horizontal pure-menu-open">
		<ul class="footer-menu">
		
		</ul>
	</div>

	<p>&copy; 2019. All rights reserved.</p>
</div>
    </div>
  </div>
	

	

  
</body>
</html>
